{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "behGg8UDyFyi",
        "outputId": "8f60f415-9354-4b8f-bce0-235e38c1d6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg171izAWKVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974cc81c-198b-4ba5-dc79-0a598ed88141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/IAOS/'\n",
        "\n",
        "\n",
        "with open(data_path+\"acknowledges.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Split the content based on the delimiter\n",
        "sections = content.split(\"---\")\n",
        "\n",
        "# Filter out blank sections\n",
        "filtered_sections = [section.strip() for section in sections if section.strip()]\n",
        "\n",
        "# Print each non-blank section\n",
        "for section in filtered_sections:\n",
        "    print(section)\n",
        "print(len(filtered_sections))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4HjBN_eyBBm",
        "outputId": "23365e67-4dd0-4923-cd63-691a0f4ab1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regarding fine-tuning, we have already started an investigation using the top N most frequently used words in our corpus. Even though we have some preliminary results, this investigation is still a work in progress.\n",
            "We thank lab members at Institute of Industrial Design of Huaqiao University for their technical support. This research was assisted by the Institute of Industrial Design of Huaqiao University and the City University of Macau, and the State Key Laboratory of Subtropical Building Science, South China University of Technology.\n",
            "Acknowledgements We acknowledge the help of all the optometrists at DMDSC for performing the digital retinal colour photography for all the patients with Remidio Fundus on phone camera and the ophthalmologists at DMDSC, Gopalapuram for the ICDR grading. We acknowledge Dr. Kaushal Solanki, Founder and CEO, EyeNuk Inc., Los Angeles, California and his team for doing the automated analysis and for providing the technical information about Eye Art software.\n",
            "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
            "This work was partly supported by Elsevier.\n",
            "Special thanks to all the participants and specifically to Prof. Ed Arens for his contributions in guiding the research project.\n",
            "The authors are grateful to Jing Ye for technological guidance. They are grateful to Xuewen Chen, Lu Li, Chaoqun Zhang, and Yingyu Mao, who works in the department of dry eye, for their help in collecting data.\n",
            "We thank all the cyclists that provided the data to build our system and agreed to be part of this project. We particularly thank the six cycling experts for taking the time to provide their expertise in cycling coaching.\n",
            "applications. We also discussed other research directions and the open challenges that face PLS in future wireless networks. In summary, our review incorporated different aspects that are related to the optimization and design of PLS systems, including secure resource allocation, channel estimation and the integration of AI into practical strategies to help PLS. We believe that this paper can provide the research community with guidance for advancing the considerations of future PLS research.\n",
            "We thank Na Jin Kim for performing the strategic literature search. We would also like to thank Ah Reum Kim for arranging the documents related to this research project.\n",
            "We thank the staff of Maier Leibnitz Laboratory Munich for the great help and support at the experiments there and Thomas Schmid for providing the cells, protocols and access to his laboratories.\n",
            "We acknowledge support by the Open Access Publication Fund of the University of Duisburg-Essen.\n",
            "Acknowledgments: We appreciate Y.I.K. for secretary assistance.\n",
            "We thank all patients for their support of our research.\n",
            "Establishing operating procedures and governance models are the fundamental concepts of the methodology proposed in this article. The presented use case demonstrates that the proposed steps help companies implement IPA successfully.\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/IAOS/'\n",
        "abstracts_file_path = data_path+\"acknowledges.txt\"\n",
        "titles_file_path = data_path+\"orden.txt\"\n",
        "\n",
        "with open(abstracts_file_path, 'r') as abstracts_file:\n",
        "    abstracts = abstracts_file.read().split('---')\n",
        "\n",
        "# Read the titles file\n",
        "with open(titles_file_path, 'r') as titles_file:\n",
        "    titles = titles_file.readlines()\n",
        "\n",
        "# Remove leading/trailing whitespaces from titles\n",
        "titles = [title.strip() for title in titles]\n",
        "\n",
        "# Match titles with abstracts (even if the abstract is blank)\n",
        "title_abstract_pairs = []\n",
        "for i, title in enumerate(titles):\n",
        "    if i < len(abstracts):\n",
        "        abstract = abstracts[i].strip()\n",
        "    else:\n",
        "        abstract = \"\"  # If there is no abstract available for a title\n",
        "    if abstract != \"null\":\n",
        "        title_abstract_pairs.append((title, abstract))\n",
        "\n",
        "# Print the title-abstract pairs\n",
        "for title, abstract in title_abstract_pairs:\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Abstract:\", abstract)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNJ8Ej_uo3a1",
        "outputId": "f1e534a4-19a7-488f-cb93-c4a7ec3ef4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: A Comparison of Several AI Techniques for Authorship Attribution on Romanian Texts\n",
            "Abstract: Regarding fine-tuning, we have already started an investigation using the top N most frequently used words in our corpus. Even though we have some preliminary results, this investigation is still a work in progress.\n",
            "\n",
            "Title: AI-Based Environmental Color System in Achieving\n",
            "Abstract: We thank lab members at Institute of Industrial Design of Huaqiao University for their technical support. This research was assisted by the Institute of Industrial Design of Huaqiao University and the City University of Macau, and the State Key Laboratory of Subtropical Building Science, South China University of Technology.\n",
            "\n",
            "Title: Automated diabetic retinopathy detection in smartphone-based fundus photography using artificial intelligenceSustainable Urban Development\n",
            "Abstract: Acknowledgements We acknowledge the help of all the optometrists at DMDSC for performing the digital retinal colour photography for all the patients with Remidio Fundus on phone camera and the ophthalmologists at DMDSC, Gopalapuram for the ICDR grading. We acknowledge Dr. Kaushal Solanki, Founder and CEO, EyeNuk Inc., Los Angeles, California and his team for doing the automated analysis and for providing the technical information about Eye Art software.\n",
            "\n",
            "Title: Attention Is All You Need\n",
            "Abstract: Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
            "\n",
            "Title: A Supervised Approach to Extractive Summarisation of Scientific Papers\n",
            "Abstract: This work was partly supported by Elsevier.\n",
            "\n",
            "Title: Artificial Intelligence for Efficient Thermal Comfort Systems Requirements, Current Applications and Future Directions\n",
            "Abstract: Special thanks to all the participants and specifically to Prof. Ed Arens for his contributions in guiding the research project.\n",
            "\n",
            "Title: Meibomian Gland Density: An Effective Evaluation Index ofMeibomian Gland Dysfunction Based on Deep Learning and Transfer Learning\n",
            "Abstract: The authors are grateful to Jing Ye for technological guidance. They are grateful to Xuewen Chen, Lu Li, Chaoqun Zhang, and Yingyu Mao, who works in the department of dry eye, for their help in collecting data.\n",
            "\n",
            "Title: Towards an AI-Based Tailored Training Planning for Road Cyclists: A Case Study\n",
            "Abstract: We thank all the cyclists that provided the data to build our system and agreed to be part of this project. We particularly thank the six cycling experts for taking the time to provide their expertise in cycling coaching.\n",
            "\n",
            "Title: A Review of Fundamental Optimization Approaches and the Role of AI Enabling Technologies in Physical Layer Security\n",
            "Abstract: applications. We also discussed other research directions and the open challenges that face PLS in future wireless networks. In summary, our review incorporated different aspects that are related to the optimization and design of PLS systems, including secure resource allocation, channel estimation and the integration of AI into practical strategies to help PLS. We believe that this paper can provide the research community with guidance for advancing the considerations of future PLS research.\n",
            "\n",
            "Title: Recent Applications of Artificial Intelligence from Histopathologic Image-Based Prediction of Microsatellite Instability in Solid Cancers: A Systematic Review\n",
            "Abstract: We thank Na Jin Kim for performing the strategic literature search. We would also like to thank Ah Reum Kim for arranging the documents related to this research project.\n",
            "\n",
            "Title: CeCILE - An Artificial Intelligence Based Cell-Detection for the Evaluation of Radiation Effects in Eucaryotic Cells\n",
            "Abstract: We thank the staff of Maier Leibnitz Laboratory Munich for the great help and support at the experiments there and Thomas Schmid for providing the cells, protocols and access to his laboratories.\n",
            "\n",
            "Title: Ensuring the Reliability of Virtual Sensors Based on Artificial Intelligence within Vehicle Dynamics Control Systems\n",
            "Abstract: We acknowledge support by the Open Access Publication Fund of the University of Duisburg-Essen.\n",
            "\n",
            "Title: Development of Anticancer Peptides Using Artificial Intelligence and Combinational Therapy for Cancer Therapeutics\n",
            "Abstract: Acknowledgments: We appreciate Y.I.K. for secretary assistance.\n",
            "\n",
            "Title: An AI-Powered Clinical Decision Support System to Predict Flares in Rheumatoid Arthritis: A Pilot Study\n",
            "Abstract: We thank all patients for their support of our research.\n",
            "\n",
            "Title: Intelligent Process Automation: An Application in Manufacturing Industry\n",
            "Abstract: Establishing operating procedures and governance models are the fundamental concepts of the methodology proposed in this article. The presented use case demonstrates that the proposed steps help companies implement IPA successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/roberta-large-ner-english\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/roberta-large-ner-english\")\n",
        "\n",
        "##### Process text sample (from wikipedia)\n",
        "\n",
        "from transformers import pipeline\n",
        "title_NER_json = []\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "output_file_path = data_path + \"title_Ner.txt\"\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "  for title, abstract in title_abstract_pairs:\n",
        "    if len(nlp(abstract))>0:\n",
        "      output_file.write(title+ '->'+str(nlp(abstract))+'\\n')\n",
        "      print(nlp(abstract))\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "F3Z2fbP9WWJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2c171b-f36d-46e2-f468-b2e22c605a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'ORG', 'score': 0.99932224, 'word': ' Institute of Industrial Design', 'start': 24, 'end': 54}, {'entity_group': 'ORG', 'score': 0.99875045, 'word': ' Huaqiao University', 'start': 58, 'end': 76}, {'entity_group': 'ORG', 'score': 0.9219733, 'word': '.', 'start': 104, 'end': 105}, {'entity_group': 'ORG', 'score': 0.9994804, 'word': ' Institute of Industrial Design', 'start': 140, 'end': 170}, {'entity_group': 'ORG', 'score': 0.99880433, 'word': ' Huaqiao University', 'start': 174, 'end': 192}, {'entity_group': 'ORG', 'score': 0.99806225, 'word': ' City University of Macau', 'start': 201, 'end': 225}, {'entity_group': 'ORG', 'score': 0.99875134, 'word': ' State Key Laboratory of Subtropical Building Science', 'start': 235, 'end': 287}, {'entity_group': 'ORG', 'score': 0.9856183, 'word': ' South China University of Technology.', 'start': 289, 'end': 326}]\n",
            "[{'entity_group': 'ORG', 'score': 0.9993308, 'word': ' DMDSC', 'start': 68, 'end': 73}, {'entity_group': 'MISC', 'score': 0.9962486, 'word': ' Remidio Fundus', 'start': 154, 'end': 168}, {'entity_group': 'ORG', 'score': 0.9975572, 'word': ' DMDSC', 'start': 213, 'end': 218}, {'entity_group': 'LOC', 'score': 0.9978603, 'word': ' Gopalapuram', 'start': 220, 'end': 231}, {'entity_group': 'MISC', 'score': 0.9738165, 'word': ' ICDR', 'start': 240, 'end': 244}, {'entity_group': 'ORG', 'score': 0.9903106, 'word': '.', 'start': 252, 'end': 253}, {'entity_group': 'PER', 'score': 0.9993343, 'word': ' Kaushal Solanki', 'start': 273, 'end': 288}, {'entity_group': 'ORG', 'score': 0.9991902, 'word': ' EyeNuk Inc', 'start': 307, 'end': 317}, {'entity_group': 'LOC', 'score': 0.9970335, 'word': ' Los Angeles', 'start': 320, 'end': 331}, {'entity_group': 'LOC', 'score': 0.99986136, 'word': ' California', 'start': 333, 'end': 343}, {'entity_group': 'MISC', 'score': 0.9688693, 'word': ' Eye Art', 'start': 440, 'end': 447}, {'entity_group': 'ORG', 'score': 0.9903106, 'word': '.', 'start': 456, 'end': 457}]\n",
            "[{'entity_group': 'PER', 'score': 0.9998439, 'word': ' Nal Kalchbrenner', 'start': 36, 'end': 52}, {'entity_group': 'PER', 'score': 0.99986655, 'word': ' Stephan Gouws', 'start': 57, 'end': 70}]\n",
            "[{'entity_group': 'ORG', 'score': 0.99699926, 'word': ' Elsevier', 'start': 34, 'end': 42}]\n",
            "[{'entity_group': 'PER', 'score': 0.9998965, 'word': ' Ed Arens', 'start': 65, 'end': 73}]\n",
            "[{'entity_group': 'PER', 'score': 0.9992676, 'word': ' Jing Ye', 'start': 28, 'end': 35}, {'entity_group': 'PER', 'score': 0.99909365, 'word': ' Xuewen Chen', 'start': 85, 'end': 96}, {'entity_group': 'PER', 'score': 0.99909735, 'word': ' Lu Li', 'start': 98, 'end': 103}, {'entity_group': 'PER', 'score': 0.99838275, 'word': ' Chaoqun Zhang', 'start': 105, 'end': 118}, {'entity_group': 'PER', 'score': 0.9990565, 'word': ' Yingyu Mao', 'start': 124, 'end': 134}]\n",
            "[{'entity_group': 'MISC', 'score': 0.94211984, 'word': ' PLS', 'start': 92, 'end': 95}, {'entity_group': 'MISC', 'score': 0.9486715, 'word': ' PLS', 'start': 230, 'end': 233}, {'entity_group': 'MISC', 'score': 0.9798284, 'word': ' AI', 'start': 323, 'end': 325}, {'entity_group': 'MISC', 'score': 0.939168, 'word': ' PLS', 'start': 360, 'end': 363}, {'entity_group': 'MISC', 'score': 0.95335186, 'word': ' PLS', 'start': 484, 'end': 487}]\n",
            "[{'entity_group': 'PER', 'score': 0.9906513, 'word': ' Na Jin Kim', 'start': 9, 'end': 19}, {'entity_group': 'PER', 'score': 0.99430853, 'word': ' Ah Reum Kim', 'start': 96, 'end': 107}]\n",
            "[{'entity_group': 'ORG', 'score': 0.99790955, 'word': ' Maier Leibnitz Laboratory Munich', 'start': 22, 'end': 54}, {'entity_group': 'PER', 'score': 0.9998471, 'word': ' Thomas Schmid', 'start': 115, 'end': 128}]\n",
            "[{'entity_group': 'ORG', 'score': 0.99462664, 'word': ' Open Access Publication Fund', 'start': 30, 'end': 58}, {'entity_group': 'ORG', 'score': 0.9917304, 'word': ' University of Duisburg-Essen.', 'start': 66, 'end': 95}]\n",
            "[{'entity_group': 'LOC', 'score': 0.8714873, 'word': ' Y.I.K.', 'start': 31, 'end': 37}, {'entity_group': 'LOC', 'score': 0.91425455, 'word': '.', 'start': 62, 'end': 63}]\n",
            "[{'entity_group': 'MISC', 'score': 0.9952113, 'word': ' IPA', 'start': 215, 'end': 218}]\n"
          ]
        }
      ]
    }
  ]
}