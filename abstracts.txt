With the proliferation of 5G mobile networks within next-generation wireless communication, the design and optimization of 5G networks are progressing in the direction of improving the physical layer security (PLS) paradigm. This phenomenon is due to the fact that traditional methods for the network optimization of PLS fail to adapt new features, technologies, and resource management to diversified demand applications. To improve these methods, future 5G and beyond 5G (B5G) networks will need to rely on new enabling technologies. Therefore, approaches for PLS design and optimization that are based on artificial intelligence (AI) and machine learning (ML) have been corroborated to outperform traditional security technologies. This will allow future 5G networks to be more intelligent and robust in order to significantly improve the performance of system design over traditional security methods. With the objective of advancing future PLS research, this review paper presents an elaborate discussion on the design and optimization approaches of wireless PLS techniques. In particular, we focus on both signal processing and information-theoretic security approaches to investigate the optimization techniques and system designs of PLS strategies. The review begins with the fundamental concepts that are associated with PLS, including a discussion on conventional cryptographic techniques and wiretap channel models. We then move on to discuss the performance metrics and basic optimization schemes that are typically adopted in PLS design strategies. The research directions for secure system designs and optimization problems are then reviewed in terms of signal processing, resource allocation and node/antenna selection. Thereafter, the applications of AI and ML technologies in the optimization and design of PLS systems are discussed. In this context, the ML-and AI-based solutions that pertain to end-to-end physical layer joint optimization, secure resource allocation and signal processing methods are presented. We finally conclude with discussions on future trends and technical challenges that are related to the topics of PLS system design and the benefits of AI technologies.
---
Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.
---
In this article I discuss the method of hand gesture recognition as a visual motion detection based on artificial intelligence by training three main movements namely, scrolling up, scrolling down and stopping based on capturing the front camera image capture speed of 3 fps and measuring its efficiency against the control movements that performed using Hidden-Markov Modeling (HMM) with each catch object scroll up 3 fps / 15 frames scroll down scroll down 3 fps / 15 frames and stop 3 fps / 9 frames, the result is that the most effective hand gesture object training movement is stop gesture with 3 fps / 9 frames because the object\'s movement is able to be recognized by the system only in the 3rd second image capture frame.
---
Confronting the age of artificial intelligence, exploring art through technology has become one of the directions of interdisciplinary development. Not only does artificial intelligence technology explore sustainability on a technical level; it can also take advantage of itself to focus on the visual perception of the living environment. People frequently interpret environmental features through their eyes, and the use of intuitive eye-tracking can provide effective data that can contribute to environmental sustainability in managing the environment and color planning to enhance the image of cities. This research investigates the visual responses of people viewing the historic city of Macau through an eye movement experiment to understand how the color characteristics of the physical environment are perceived. The research reveals that the buildings and plantings in the historic district of Macau are the most visible objects in the environment, while the smaller scale of St. Dominic\'s Square, the Company of Jesus Square, and St. Augustine\'s Square, which have a sense of spatial extension, have also become iconic environmental landscapes. This also draws visual attention and guides the direction of travel. The overall impressions of the Historic Centre of Macau, as expressed by the participants after the eye movement experiment, were mainly described as "multiculturalism", "architectural style", "traditional architecture", "color scheme", and "garden planting". The 60 colors representing the urban color of Macau are then organized around these deep feelings about the environment. Therefore, for future inspiration, the 60 colors can be applied through design practice to create color expressions that fit the local characteristics, and thereby enhance the overall visual image of the city.
---
Treat-to-target (T2T) is a main therapeutic strategy in rheumatology; however, patients and rheumatologists currently have little support in making the best treatment decision. Clinical decision support systems (CDSSs) could offer this support. The aim of this study was to investigate the accuracy, effectiveness, usability, and acceptance of such a CDSS-Rheuma Care Manager (RCM)-including an artificial intelligence (AI)-powered flare risk prediction tool to support the management of rheumatoid arthritis (RA). Longitudinal clinical routine data of RA patients were used to develop and test the RCM. Based on ten real-world patient vignettes, five physicians were asked to assess patients\' flare risk, provide a treatment decision, and assess their decision confidence without and with access to the RCM for predicting flare risk. RCM usability and acceptance were assessed using the system usability scale (SUS) and net promoter score (NPS). The flare prediction tool reached a sensitivity of 72%, a specificity of 76%, and an AUROC of 0.80. Perceived flare risk and treatment decisions varied largely between physicians. Having access to the flare risk prediction feature numerically increased decision confidence (3.5/5 to 3.7/5), reduced deviations between physicians and the prediction tool (20% to 12% for half dosage flare prediction), and resulted in more treatment reductions (42% to 50% vs. 20%). RCM usability (SUS) was rated as good (82/100) and was well accepted (mean NPS score 7/10). CDSS usage could support physicians by decreasing assessment deviations and increasing treatment decision confidence.
---
This study examines the current state of artificial intelligence (AI)-based technology applications and their impact on the healthcare industry. In addition to a thorough review of the literature, this study analyzed several real-world examples of AI applications in healthcare. The results indicate that major hospitals are, at present, using AI-enabled systems to augment medical staff in patient diagnosis and treatment activities for a wide range of diseases. In addition, AI systems are making an impact on improving the efficiency of nursing and managerial activities of hospitals. While AI is being embraced positively by healthcare providers, its applications provide both the utopian perspective (new opportunities) and the dystopian view (challenges to overcome). We discuss the details of those opportunities and challenges to provide a balanced view of the value of AI applications in healthcare. It is clear that rapid advances of AI and related technologies will help care providers create new value for their patients and improve the efficiency of their operational processes. Nevertheless, effective applications of AI will require effective planning and strategies to transform the entire care service and operations to reap the benefits of what technologies offer.
---

---
In the construction industry, non-destructive testing (NDT) methods are often used in the field to inspect the compressive strength of concrete. NDT methods do not cause damage to the existing structure and are relatively economical. Two popular NDT methods are the rebound hammer (RH) test and the ultrasonic pulse velocity (UPV) test. One major drawback of the RH test and UPV test is that the concrete compressive strength estimations are not very accurate when comparing them to the results obtained from the destructive tests. To improve concrete strength estimation, the researchers applied artificial intelligence prediction models to explore the relationships between the input values (results from the two NDT tests) and the output values (concrete strength). In-situ NDT data from a total of 98 samples were collected in collaboration with a material testing laboratory and the Professional Civil Engineer Association. In-situ NDT data were used to develop and validate the prediction models (both traditional statistical models and AI models). The analysis results showed that AI prediction models provide more accurate estimations when compared to statistical regression models. The research results show significant improvement when AI techniques (ANNs, SVM and ANFIS) are applied to estimate concrete compressive strength in RH and UPV tests.
---
In buildings, one or a combination of systems (e.g., central HVAC system, ceiling fan, desk fan, personal heater, and foot warmer) are often responsible for providing thermal comfort to the occupants. While thermal comfort has been shown to differ from person to person and vary over time, these systems are often operated based on prefixed setpoints and schedule of operations or at the request/routine of each individual. This leads to occupants\' discomfort and energy wastes. To enable the improvements in both comfort and energy efficiency autonomously, in this paper, we describe the necessity of an integrated system of sensors (e.g., wearable sensors/infrared sensors), infrastructure for enabling system interoperability, learning and control algorithms, and actuators (e.g., HVAC system setpoints, ceiling fans) to work under a governing central intelligent system. To assist readers with little to no exposure to artificial intelligence (AI), we describe the fundamentals of an intelligent entity (rational agent) and components of its problem-solving process (i.e., search algorithms, logic inference, and machine learning) and provide examples from the literature. We then discuss the current application of intelligent personal thermal comfort systems in buildings based on a comprehensive review of the literature. We finally describe future directions for enabling application of fully automated systems to provide comfort in an efficient manner. It is apparent that improvements in all aspects of an intelligent system are be needed to better ascertain the correct combination of systems to activate and for how long to increase the overall efficiency of the system and improve comfort.
---
In the global epidemic era, oral problems significantly impact a major population of children. The key to a child\'s optimal health is early diagnosis, prevention, and treatment of these disorders. In recent years, the field of artificial intelligence (AI) has seen tremendous pace and progress. As a result, AI\'s infiltration is witnessed even in those areas that were traditionally thought to be best left to human specialists. The ultimate ability to improve patient care and make precise diagnoses of illnesses has revolutionized the world of healthcare. In the field of dentistry, the competence to execute treatment measures while still providing appropriate patient behavior counseling is in high demand, particularly in the field of pediatric dental care. As a result, we decided to conduct this review specifically to examine the applications of AI models in pediatric dentistry. A comprehensive search of the subjects was done using a wide range of databases to look for studies that have been published in peer-reviewed journals from its inception until 31 December 2022. After the application of the criteria, only 25 of the 351 articles were taken into consideration for this review. According to the literature, AI is frequently used in pediatric dentistry for the purpose of making an accurate diagnosis and assisting clinicians, dentists, and pediatric dentists in clinical decision making, developing preventive strategies, and establishing an appropriate treatment plan.
---
The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. * Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.
---
Neural Machine Translation (NMT) models usually use large target vocabulary sizes to capture most of the words in the target language. The vocabulary size is a big factor when decoding new sentences as the final softmax layer normalizes over all possible target words. To address this problem, it is widely common to restrict the target vocabulary with candidate lists based on the source sentence. Usually, the candidate lists are a combination of external word-to-word aligner, phrase table entries or most frequent words. In this work, we propose a simple and yet novel approach to learn candidate lists directly from the attention layer during NMT training. The candidate lists are highly optimized for the current NMT model and do not need any external computation of the candidate pool. We show significant decoding speedup compared with using the entire vocabulary, without losing any translation quality for two language pairs.
---
Objectives To assess the role of artificial intelligence (AI)-based automated software for detection of diabetic retinopathy (DR) and sight-threatening DR (STDR) by fundus photography taken using a smartphone-based device and validate it against ophthalmologist\'s grading. Methods Three hundred and one patients with type 2 diabetes underwent retinal photography with Remidio \'Fundus on phone\' (FOP), a smartphone-based device, at a tertiary care diabetes centre in India. Grading of DR was performed by the ophthalmologists using International Clinical DR (ICDR) classification scale. STDR was defined by the presence of severe non-proliferative DR, proliferative DR or diabetic macular oedema (DME). The retinal photographs were graded using a validated AI DR screening software (EyeArt TM ) designed to identify DR, referable DR (moderate non-proliferative DR or worse and/or DME) or STDR. The sensitivity and specificity of automated grading were assessed and validated against the ophthalmologists\' grading. Results Retinal images of 296 patients were graded. DR was detected by the ophthalmologists in 191 (64.5%) and by the AI software in 203 (68.6%) patients while STDR was detected in 112 (37.8%) and 146 (49.3%) patients, respectively. The AI software showed 95.8% (95% CI 92.9-98.7) sensitivity and 80.2% (95% CI 72.6-87.8) specificity for detecting any DR and 99.1% (95% CI 95.1-99.9) sensitivity and 80.4% (95% CI 73.9-85.9) specificity in detecting STDR with a kappa agreement of k = 0.78 (p &lt; 0.001) and k = 0.75 (p &lt; 0.001), respectively. Conclusions Automated AI analysis of FOP smartphone retinal imaging has very high sensitivity for detecting DR and STDR and thus can be an initial tool for mass retinal screening in people with diabetes.
---
The fundamental basis in the development of novel radiotherapy methods is in-vitro cellular studies. To assess different endpoints of cellular reactions to irradiation like proliferation, cell cycle arrest, and cell death, several assays are used in radiobiological research as standard methods. For example, colony forming assay investigates cell survival and Caspase3/7-Sytox assay cell death. The major limitation of these assays is the analysis at a fixed timepoint after irradiation. Thus, not much is known about the reactions before or after the assay is performed. Additionally, these assays need special treatments, which influence cell behavior and health. In this study, a completely new method is proposed to tackle these challenges: A deep-learning algorithm called CeCILE (Cell Classification and In-vitro Lifecycle Evaluation), which is used to detect and analyze cells on videos obtained from phase-contrast microscopy. With this method, we can observe and analyze the behavior and the health conditions of single cells over several days after treatment, up to a sample size of 100 cells per image frame. To train CeCILE, we built a dataset by labeling cells on microscopic images and assign class labels to each cell, which define the cell states in the cell cycle. After successful training of CeCILE, we irradiated CHO-K1 cells with 4 Gy protons, imaged them for 2 days by a microscope equipped with a live-cell-imaging set-up, and analyzed the videos by CeCILE and by hand.
---
In this paper, online deep learning (DL)-based channel estimation algorithm for doubly selective fading channels is proposed by employing the deep neural network (DNN). With properly selected inputs, the DNN can not only exploit the features of channel variation from previous channel estimates but also extract additional features from pilots and received signals. Moreover, the DNN can take the advantages of the least squares estimation to further improve the performance of channel estimation. The DNN is first trained with simulated data in an off-line manner and then it could track the dynamic channel in an online manner. To reduce the performance degradation from random initialization, a pre-training approach is designed to refine the initial parameters of the DNN with several epochs of training. The proposed algorithm benefits from the excellent learning and generalization capability of DL and requires no prior knowledge about the channel statistics. Hence, it is more suitable for communication systems with modeling errors or non-stationary channels, such as high-mobility vehicular systems, underwater acoustic systems, and molecular communication systems. The numerical results show that the proposed DL-based algorithm outperforms the existing estimator in terms of both efficiency and robustness, especially when the channel statistics are time-varying.
---
Machine learning models are built using training data, which is collected from human experience and is prone to bias. Humans demonstrate a cognitive bias in their thinking and behavior, which is ultimately reflected in the collected data. From Amazon\'s hiring system, which was built using ten years of human hiring experience, to a judicial system that was trained using human judging practices, these systems all include some element of bias. The best machine learning models are said to mimic humans\' cognitive ability, and thus such models are also inclined towards bias. However, detecting and evaluating bias is a very important step for better explainable models. In this work, we aim to explain bias in learning models in relation to humans\' cognitive bias and propose a wrapper technique to detect and evaluate bias in machine learning models using an openly accessible dataset from UCI Machine Learning Repository. In the deployed dataset, the potentially biased attributes (PBAs) are gender and race. This study introduces the concept of alternation functions to swap the values of PBAs, and evaluates the impact on prediction using KL divergence. Results demonstrate females and Asians to be associated with low wages, placing some open research questions for the research community to ponder over.
---
Cancer is a group of diseases causing abnormal cell growth, altering the genome, and invading or spreading to other parts of the body. Among therapeutic peptide drugs, anticancer peptides (ACPs) have been considered to target and kill cancer cells because cancer cells have unique characteristics such as a high negative charge and abundance of microvilli in the cell membrane when compared to a normal cell. ACPs have several advantages, such as high specificity, cost-effectiveness, low immunogenicity, minimal toxicity, and high tolerance under normal physiological conditions. However, the development and identification of ACPs are time-consuming and expensive in traditional wet-lab-based approaches. Thus, the application of artificial intelligence on the approaches can save time and reduce the cost to identify candidate ACPs. Recently, machine learning (ML), deep learning (DL), and hybrid learning (ML combined DL) have emerged into the development of ACPs without experimental analysis, owing to advances in computer power and big data from the power system. Additionally, we suggest that combination therapy with classical approaches and ACPs might be one of the impactful approaches to increase the efficiency of cancer therapy.
---
An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT\'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1
---
Technological advancements in education have turned the idea of machines as teachers into a reality. To better understand this phenomenon, the present study explores how college students develop expectations (or anticipations) about a machine teacher, particularly an AI teaching assistant. Specifically, the study examines whether students\' previous experiences with online courses taught by a human teacher would influence their expectations about AI teaching assistants in future online courses. An online survey was conducted to collect data from college students in the United States. Findings indicate that positively experienced social presence of a human teacher helps develop positive expectations about an AI teaching assistant. The study provides meaningful implications and contributions to our understanding of a machine agent in education.
---
We study the representation and encoding of phonemes in a recurrent neural network model of grounded speech. We use a model which processes images and their spoken descriptions, and projects the visual and auditory representations into the same semantic space. We perform a number of analyses on how information about individual phonemes is encoded in the MFCC features extracted from the speech signal, and the activations of the layers of the model. Via experiments with phoneme decoding and phoneme discrimination we show that phoneme representations are most salient in the lower layers of the model, where low-level signals are processed at a fine-grained level, although a large amount of phonological information is retain at the top recurrent layer. We further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy. Moreover, a hierarchical clustering of phoneme representations learned by the network shows an organizational structure of phonemes similar to those proposed in linguistics.
---
The use of virtual sensors in vehicles represents a cost-effective alternative to the installation of physical hardware. In addition to physical models resulting from theoretical modeling, artificial intelligence and machine learning approaches are increasingly used, which incorporate experimental modeling. Due to the resulting black-box characteristics, virtual sensors based on artificial intelligence are not fully reliable, which can have fatal consequences in safety-critical applications. Therefore, a hybrid method is presented that safeguards the reliability of artificial intelligence-based estimations. The application example is the state estimation of the vehicle roll angle. The state estimation is coupled with a central predictive vehicle dynamics control. The implementation and validation is performed by a co-simulation between IPG CarMaker and MATLAB/Simulink. By using the hybrid method, unreliable estimations by the artificial intelligence-based model resulting from erroneous input signals are detected and handled. Thus, a valid and reliable state estimate is available throughout.
---
Background: The intelligent processes automation has been cataloged as one of the most potential and strategic technology solutions to develop a corporate digital transformation. Method: This paper introduces essential concepts to create Intelligent Process Automation (IPA) in industries and proposes a framework to implement IPA technologies successfully. The approach involves: firstly, assembling a good implementation setup and deeply researching the process using process mining techniques. Secondly, choosing and locating the best AI technology inside the IPA. Finally, defining an appropriate architecture of the IPA. Results: The paper illustrates an IPA use case in the manufacturing industry, where it is possible to automate the process of sending production orders to a manufacturing plant and optimize waste and plant capacity significantly. Conclusions: The research depicts the potential of intelligent process automation and its quantifiable benefits in the manufacturing process, and the contribution can be applied to different enterprises with a global context.
---
Determining the author of a text is a difficult task. Here, we compare multiple Artificial Intelligence techniques for classifying literary texts written by multiple authors by taking into account a limited number of speech parts (prepositions, adverbs, and conjunctions). We also introduce a new dataset composed of texts written in the Romanian language on which we have run the algorithms. The compared methods are artificial neural networks, multi-expression programming, k-nearest neighbour, support vector machines, and decision trees with C5.0. Numerical experiments show, first of all, that the problem is difficult, but some algorithms are able to generate acceptable error rates on the test set.
---
We aimed to establish an artificial intelligence (AI) system based on deep learning and transfer learning for meibomian gland (MG) segmentation and evaluate the efficacy of MG density in the diagnosis of MG dysfunction (MGD). First, 85 eyes of 85 subjects were enrolled for AI system-based evaluation effectiveness testing. Then, from 2420 randomly selected subjects, 4006 meibography images (1620 upper eyelids and 2386 lower eyelids) graded by three experts according to the meiboscore were analyzed for MG density using the AI system. The updated AI system achieved 92% accuracy (intersection over union, IoU) and 100% repeatability in MG segmentation after 4 h of training. The processing time for each meibography was 100 ms. We discovered a significant and linear correlation between MG density and ocular surface disease index questionnaire (OSDI), tear break-up time (TBUT), lid margin score, meiboscore, and meibum expressibility score (all p &lt; 0.05). The area under the curve (AUC) was 0.900 for MG density in the total eyelids. The sensitivity and specificity were 88% and 81%, respectively, at a cutoff value of 0.275. MG density is an effective index for MGD, particularly supported by the AI system, which could replace the meiboscore, significantly improve the accuracy of meibography analysis, reduce the analysis time and doctors\' workload, and improve the diagnostic efficiency.
---
The ability to accurately perceive whether a speaker is asking a question or is making a statement is crucial for any successful interaction. However, learning and classifying tonal patterns has been a challenging task for automatic speech recognition and for models of tonal representation, as tonal contours are characterized by significant variation. This paper provides a classification model of Cypriot Greek questions and statements. We evaluate two state-of-the-art network architectures: a Long Short-Term Memory (LSTM) network and a convolutional network (ConvNet). The ConvNet outperforms the LSTM in the classification task and exhibited an excellent performance with 95% classification accuracy.
---
As part of "intelligence," the "awareness" is the state or ability to perceive, feel, or be mindful of events, objects, or sensory patterns: in other words, to be conscious of the surrounding environment and its interactions. Inspired by early-ages human skills developments and especially by early-ages awareness maturation, the present paper accosts the robots intelligence from a different slant directing the attention to combining both "cognitive" and "perceptual" abilities. Within such a slant, the machine (robot) shrewdness is constructed on the basis of a multilevel cognitive concept attempting to handle complex artificial behaviors. The intended complex behavior is the autonomous discovering of objects by robot exploring an unknown environment: in other words, proffering the robot autonomy and awareness in and about unknown backdrop.
---
The adoption of artificial intelligence in post-earthquake inspections and reconnaissance has received considerable attention in recent years, owing to its exponential increase in computation capabilities and inherent potential in addressing disadvantages associated with manual inspections. Herein, we present the effectiveness of automated deep learning in enhancing the assessment of damage caused by the 2017 Pohang earthquake. Six classical pre-trained convolutional neural network (CNN) models are implemented through transfer learning (TL) on a small dataset, comprising 1780 manually labeled images of structural damage. Feature extraction and fine-tuning TL methods are trained on the image datasets. The performances of various CNN models are compared on a testing image dataset. Results confirm that the MobileNet fine-tuned model offers the best performance. Therefore, the model is further developed as a web-based application for classifying earthquake damage. The severity of damage is quantified by assigning damage assessment values, derived using the CNN model and gradient-weighted class activation mapping. The web-based application can effectively and automatically classify structural damage resulting from earthquakes, rendering it suitable for decision making, such as in resource allocation, policy development, and emergency response.
---
Although the evaluation of microsatellite instability (MSI) is important for immunotherapy, it is not feasible to test MSI in all cancers due to the additional cost and time. Recently, artificial intelligence (AI)-based MSI prediction models from whole slide images (WSIs) are being developed and have shown promising results. However, these models are still at their elementary level, with limited data for validation. This study aimed to assess the current status of AI applications to WSI-based MSI prediction and to suggest a better study design. The performance of the MSI prediction models were promising, but a small dataset, lack of external validation, and lack of a multiethnic population dataset were the major limitations. Through a combination with high-sensitivity tests such as polymerase chain reaction and immunohistochemical stains, AI-based MSI prediction models with a high performance and appropriate large datasets will reduce the cost and time for MSI testing and will be able to enhance the immunotherapy treatment process in the near future.
---
This work proposes a smart crop growth monitoring system that contains an adaptive cryptography engine to ensure the security of sensor data and an edge artificial intelligence (AI) based estimator to classify the pest and disease severity (PDS) of target crops. Based on the smart system management mechanism, cryptographic functions can be adapted to varying and real-time requirements, while the actuators can be controlled to interact with the physical world to ensure the healthy growth of crops. Experiments show when all the four cryptographic hardware modules, including RTEA32, RTEA64, XTEA32 and XTEA64, are supported, using the adaptive cryptography engine, 72.4% of slice LUTs and 68.4% of slice registers in terms of the Xilinx Zynq-7000 XC7Z020 chip can be saved. Through the smart system management mechanism, a power consumption of 0.009 watts can be reduced. Furthermore, using the binarized neural network (BNN) hardware module of the PDS estimator, the recognition accuracy of target crops i.e. dragon fruits can achieve 76.57%. Compared to the microprocessor-based design and the GPU accelerated one, the same BNN architecture on the FPGA can accelerate the frames per second by a factor of 4,919.29 and a factor of 1.08, respectively.
---
In a world where the data is a central piece, we provide a novel technique to design training plans for road cyclists. This study exposes an in-depth review of a virtual coach based on state-of-theart artificial intelligence techniques to schedule road cycling training sessions. Together with a dozen of road cycling participants\' training data, we were able to create and verify an e-coach dedicated to any level of road cyclists. The system can provide near-human coaching advice on the training of cycling athletes based on their past capabilities. In this case study, we extend the tests of our empirical research project and analyze the results provided by experts. Results of the conducted experiments show that the computational intelligence of our system can compete with human coaches at training planification. In this case study, we evaluate the system we previously developed and provide new insights and paths of amelioration for systems based on artificial intelligence for athletes. We observe that our system performs equal or better than the control training plans in 14 and 24 week training periods where it was evaluated as better in 4 of our 5 test components. We also report a higher statistical difference in the results of the experts\' evaluations between the control and virtual coach training plan (24 weeks; training load: X 2 = 4.751; resting time quantity: X 2 = 3.040; resting time distance: X 2 = 2.550; efficiency: X 2 = 2.142).
---
